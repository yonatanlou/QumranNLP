{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T11:07:15.146574Z",
     "start_time": "2024-04-04T11:07:08.836291Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from BertClassifier import BertClassifier\n",
    "from config import BASE_DIR\n",
    "text_files_dir = f\"{BASE_DIR}/data/hebrew_processed_files/2024-04-03_sectarian_classification\""
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "text = pd.read_csv(f\"{text_files_dir}/DSS_sectarian_nonbib_text.txt\", header=None, names=[\"text\"])\n",
    "labels = pd.read_csv(f\"{text_files_dir}/DSS_sectarian_nonbib_labels.txt\",sep=\"\\t\",header=None, names=[\"place\", \"training\", \"label\"])\n",
    "assert text.shape[0]==labels.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T11:07:15.183920Z",
     "start_time": "2024-04-04T11:07:15.150976Z"
    }
   },
   "id": "6b5dec2a081189d9",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                     text  training\nlabel                              \nnon_sectarian_texts   246       246\nsectarian_texts      1730      1730",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>training</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>non_sectarian_texts</th>\n      <td>246</td>\n      <td>246</td>\n    </tr>\n    <tr>\n      <th>sectarian_texts</th>\n      <td>1730</td>\n      <td>1730</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([text,labels],axis=1)[[\"text\",\"training\",\"label\"]]\n",
    "df = df.dropna()\n",
    "df.groupby(\"label\").count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T11:07:15.220411Z",
     "start_time": "2024-04-04T11:07:15.186874Z"
    }
   },
   "id": "76f4d61dd7bf6f2a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonatanlou/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yonatanlou/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yonatanlou/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "'                     precision    recall  f1-score   support\\n\\nnon_sectarian_texts       0.00      0.00      0.00        53\\n    sectarian_texts       0.87      1.00      0.93       370\\n\\n           accuracy                           0.87       423\\n          macro avg       0.44      0.50      0.47       423\\n       weighted avg       0.77      0.87      0.82       423\\n'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Removing rows with missing 'text' values\n",
    "df_clean = df.dropna(subset=['text'])\n",
    "\n",
    "# Vectorizing the text column\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(df_clean['text'])\n",
    "\n",
    "# Preparing the labels\n",
    "y = df_clean['label']\n",
    "\n",
    "# Splitting the dataset into training and test sets based on the 'training' column\n",
    "X_train = X[df_clean['training'] == 'train']\n",
    "y_train = y[df_clean['training'] == 'train']\n",
    "X_test = X[df_clean['training'] == 'test']\n",
    "y_test = y[df_clean['training'] == 'test']\n",
    "\n",
    "# Training a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "\n",
    "classification_report_result\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T11:07:15.624024Z",
     "start_time": "2024-04-04T11:07:15.226056Z"
    }
   },
   "id": "c9d06081f2a7b0ac",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "non_sectarian_texts       0.00      0.00      0.00        53\n",
      "    sectarian_texts       0.87      1.00      0.93       370\n",
      "\n",
      "           accuracy                           0.87       423\n",
      "          macro avg       0.44      0.50      0.47       423\n",
      "       weighted avg       0.77      0.87      0.82       423\n"
     ]
    }
   ],
   "source": [
    "print(classification_report_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T11:07:15.634699Z",
     "start_time": "2024-04-04T11:07:15.627494Z"
    }
   },
   "id": "baf8fbe3a0273963",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from BertClassifier import BertClassifier\n",
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "tokenizer = BertTokenizer.from_pretrained(\"onlplab/alephbert-base\")\n",
    "LR = 1e-6\n",
    "# section_type = [\"nonbib\", \"bib\"]\n",
    "section_type = ['sectarian_texts', 'non_sectarian_texts']\n",
    "\n",
    "\n",
    "train_data, train_label = np.array([]), np.array([], dtype=int)\n",
    "val_data, val_label = np.array([]), np.array([], dtype=int)\n",
    "test_data, test_label = np.array([]), np.array([], dtype=int)\n",
    "\n",
    "# size = [0 for i in section_type]\n",
    "# for i in range(len(section_type)):\n",
    "#     all_data = np.array([])\n",
    "#     all_labels = np.array([], dtype=int)\n",
    "#     section = section_type[i]\n",
    "#     book_dict, book_to_section = generate_books_dict(\n",
    "#         BOOKS_TO_RUN_ON, \"all_sectarian_texts.yaml\"\n",
    "#     )\n",
    "#     data = parser_data.get_dss_data(book_dict, section)\n",
    "#     for book_name, book_data in data.items():\n",
    "#         if len(book_data) < 100:\n",
    "#             print(book_name)\n",
    "#             continue\n",
    "#         book_scores = [section, book_name]\n",
    "#         samples, sample_names = parser_data.get_samples(book_data)\n",
    "#         preprocessed_samples = aleph_bert_preprocessing(samples)\n",
    "#         labels = [i for _ in range(len(samples))]\n",
    "#         all_data = np.concatenate((all_data, preprocessed_samples))\n",
    "#         all_labels = np.concatenate((all_labels, labels))\n",
    "#     size[i] = len(all_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T11:07:31.121193Z",
     "start_time": "2024-04-04T11:07:28.476931Z"
    }
   },
   "id": "319211488ed0ebdf",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text training  \\\n0     שבועות. ובארבעה לשבוע החמישי שמחו וידע אדם שני...    train   \n1     תחת הבל כיא הרגו קין. בשבוע הששי הוליד את אזור...    train   \n2     ובשנת אחת לשבוע הריאשון ליובל החמישי נבנו הבתי...    train   \n3     עוד תשעה בנים ובשבוע החמישי. לקח אנוש את אחותו...    train   \n4     לקח לו קינן אשה את אחותו מהללת לאשה. ותלד לו ב...    train   \n...                                                 ...      ...   \n1973  מעיר הקדש וישענו על אל בקץ מעל ישראל ויטמאו את...     test   \n1974  וכל אשר פרצו את גבול התורה מבאי הברית בהופע כב...     test   \n1975  לצאת ולבוא על פי התורה וישמעו לקול מורה ויתודו...     test   \n1976  ולא ירימו יד על חקי קדשו ומשפטי צדקו ועדוות אמ...     test   \n1977  חקי הצדק בשמעם אתם ישישו וישמחו ויעז לבם. ויתג...     test   \n\n                    label  \n0     non_sectarian_texts  \n1     non_sectarian_texts  \n2     non_sectarian_texts  \n3     non_sectarian_texts  \n4     non_sectarian_texts  \n...                   ...  \n1973      sectarian_texts  \n1974      sectarian_texts  \n1975      sectarian_texts  \n1976      sectarian_texts  \n1977      sectarian_texts  \n\n[1976 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>training</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>שבועות. ובארבעה לשבוע החמישי שמחו וידע אדם שני...</td>\n      <td>train</td>\n      <td>non_sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>תחת הבל כיא הרגו קין. בשבוע הששי הוליד את אזור...</td>\n      <td>train</td>\n      <td>non_sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ובשנת אחת לשבוע הריאשון ליובל החמישי נבנו הבתי...</td>\n      <td>train</td>\n      <td>non_sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>עוד תשעה בנים ובשבוע החמישי. לקח אנוש את אחותו...</td>\n      <td>train</td>\n      <td>non_sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>לקח לו קינן אשה את אחותו מהללת לאשה. ותלד לו ב...</td>\n      <td>train</td>\n      <td>non_sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1973</th>\n      <td>מעיר הקדש וישענו על אל בקץ מעל ישראל ויטמאו את...</td>\n      <td>test</td>\n      <td>sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>1974</th>\n      <td>וכל אשר פרצו את גבול התורה מבאי הברית בהופע כב...</td>\n      <td>test</td>\n      <td>sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>1975</th>\n      <td>לצאת ולבוא על פי התורה וישמעו לקול מורה ויתודו...</td>\n      <td>test</td>\n      <td>sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>1976</th>\n      <td>ולא ירימו יד על חקי קדשו ומשפטי צדקו ועדוות אמ...</td>\n      <td>test</td>\n      <td>sectarian_texts</td>\n    </tr>\n    <tr>\n      <th>1977</th>\n      <td>חקי הצדק בשמעם אתם ישישו וישמחו ויעז לבם. ויתג...</td>\n      <td>test</td>\n      <td>sectarian_texts</td>\n    </tr>\n  </tbody>\n</table>\n<p>1976 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T12:18:42.083358Z",
     "start_time": "2024-04-04T12:18:42.068771Z"
    }
   },
   "id": "b0ea727ad3e75d4",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <U15",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m Dataset(val_data, val_label)\n\u001B[1;32m     21\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m Dataset(test_data, test_label)\n\u001B[0;32m---> 23\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/QumranNLP/BertClassifier.py:103\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train, val, learning_rate, epochs)\u001B[0m\n\u001B[1;32m    100\u001B[0m total_acc_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    101\u001B[0m total_loss_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_input, train_label \u001B[38;5;129;01min\u001B[39;00m tqdm(train_dataloader):\n\u001B[1;32m    104\u001B[0m     train_label \u001B[38;5;241m=\u001B[39m train_label\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    105\u001B[0m     mask \u001B[38;5;241m=\u001B[39m train_input\u001B[38;5;241m.\u001B[39mdata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/tqdm/std.py:1182\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1179\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1182\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1185\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    676\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 677\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    678\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    679\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    205\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001B[39;00m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    139\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    139\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[0;32m--> 119\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.0/envs/QumranNLP/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:169\u001B[0m, in \u001B[0;36mcollate_numpy_array_fn\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;66;03m# array of string classes and object\u001B[39;00m\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np_str_obj_array_pattern\u001B[38;5;241m.\u001B[39msearch(elem\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mstr) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 169\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem\u001B[38;5;241m.\u001B[39mdtype))\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m collate([torch\u001B[38;5;241m.\u001B[39mas_tensor(b) \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map)\n",
      "\u001B[0;31mTypeError\u001B[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <U15"
     ]
    }
   ],
   "source": [
    "from BertClassifier import Dataset, train\n",
    "all_data = df[\"text\"].to_numpy()\n",
    "all_labels = df[\"label\"].to_numpy()\n",
    "train_size = int(0.7*len(all_data))\n",
    "val_size = int(0.1*len(all_data))\n",
    "test_size = len(all_data) - train_size - val_size\n",
    "idx = np.arange(len(all_data))\n",
    "np.random.shuffle(idx)\n",
    "train_data, train_label = np.concatenate(\n",
    "    (train_data, all_data[ :train_size])\n",
    "), np.concatenate((train_label, all_labels[:train_size]))\n",
    "val_data, val_label = np.concatenate(\n",
    "    (val_data, all_data[train_size : train_size + val_size])\n",
    "), np.concatenate((val_label, all_labels[train_size : train_size + val_size]))\n",
    "test_data, test_label = np.concatenate(\n",
    "    (test_data, all_data[test_size:])\n",
    "), np.concatenate((test_label, all_labels[test_size:]))\n",
    "\n",
    "train_dataset = Dataset(train_data, train_label)\n",
    "val_dataset = Dataset(val_data, val_label)\n",
    "test_dataset = Dataset(test_data, test_label)\n",
    "\n",
    "train(model, train_dataset, val_dataset, LR, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T12:23:44.569824Z",
     "start_time": "2024-04-04T12:23:40.350445Z"
    }
   },
   "id": "db577f1f788c323a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['sectarian_texts', 'sectarian_texts', 'sectarian_texts', ...,\n       'sectarian_texts', 'sectarian_texts', 'sectarian_texts'],\n      dtype=object)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test_dataset)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T12:25:37.058399Z",
     "start_time": "2024-04-04T12:25:37.051054Z"
    }
   },
   "id": "2af2e61898f8f0c3",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text training  label\n0     שבועות. ובארבעה לשבוע החמישי שמחו וידע אדם שני...    train      0\n1     תחת הבל כיא הרגו קין. בשבוע הששי הוליד את אזור...    train      0\n2     ובשנת אחת לשבוע הריאשון ליובל החמישי נבנו הבתי...    train      0\n3     עוד תשעה בנים ובשבוע החמישי. לקח אנוש את אחותו...    train      0\n4     לקח לו קינן אשה את אחותו מהללת לאשה. ותלד לו ב...    train      0\n...                                                 ...      ...    ...\n1973  מעיר הקדש וישענו על אל בקץ מעל ישראל ויטמאו את...     test      1\n1974  וכל אשר פרצו את גבול התורה מבאי הברית בהופע כב...     test      1\n1975  לצאת ולבוא על פי התורה וישמעו לקול מורה ויתודו...     test      1\n1976  ולא ירימו יד על חקי קדשו ומשפטי צדקו ועדוות אמ...     test      1\n1977  חקי הצדק בשמעם אתם ישישו וישמחו ויעז לבם. ויתג...     test      1\n\n[1976 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>training</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>שבועות. ובארבעה לשבוע החמישי שמחו וידע אדם שני...</td>\n      <td>train</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>תחת הבל כיא הרגו קין. בשבוע הששי הוליד את אזור...</td>\n      <td>train</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ובשנת אחת לשבוע הריאשון ליובל החמישי נבנו הבתי...</td>\n      <td>train</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>עוד תשעה בנים ובשבוע החמישי. לקח אנוש את אחותו...</td>\n      <td>train</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>לקח לו קינן אשה את אחותו מהללת לאשה. ותלד לו ב...</td>\n      <td>train</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1973</th>\n      <td>מעיר הקדש וישענו על אל בקץ מעל ישראל ויטמאו את...</td>\n      <td>test</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1974</th>\n      <td>וכל אשר פרצו את גבול התורה מבאי הברית בהופע כב...</td>\n      <td>test</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1975</th>\n      <td>לצאת ולבוא על פי התורה וישמעו לקול מורה ויתודו...</td>\n      <td>test</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1976</th>\n      <td>ולא ירימו יד על חקי קדשו ומשפטי צדקו ועדוות אמ...</td>\n      <td>test</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1977</th>\n      <td>חקי הצדק בשמעם אתם ישישו וישמחו ויעז לבם. ויתג...</td>\n      <td>test</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1976 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.arange(len(all_data))\n",
    "np.random.shuffle(idx)\n",
    "test_size = int(len(all_data) * 0.15)\n",
    "test_data, test_label = np.concatenate(\n",
    "    (test_data, all_data[:test_size])\n",
    "), np.concatenate((test_label, all_labels[:test_size]))\n",
    "val_data, val_label = np.concatenate(\n",
    "    (val_data, all_data[test_size : 2 * test_size])\n",
    "), np.concatenate((val_label, all_labels[test_size : 2 * test_size]))\n",
    "train_data, train_label = np.concatenate(\n",
    "    (train_data, all_data[2 * test_size :])\n",
    "), np.concatenate((train_label, all_labels[2 * test_size :]))\n",
    "\n",
    "print(size)\n",
    "train_dataset = Dataset(train_data, train_label)\n",
    "val_dataset = Dataset(val_data, val_label)\n",
    "test_dataset = Dataset(test_data, test_label)\n",
    "\n",
    "train(model, train_dataset, val_dataset, LR, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T11:00:32.615360Z",
     "start_time": "2024-04-04T11:00:32.601993Z"
    }
   },
   "id": "d556b21178d05dca",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[04-05 11:07:55] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 10000 lines\n",
      "[04-05 11:07:55] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 20000 lines\n",
      "[04-05 11:07:56] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 30000 lines\n",
      "[04-05 11:07:56] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 40000 lines\n",
      "[04-05 11:07:56] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 50000 lines\n",
      "[04-05 11:07:57] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 60000 lines\n",
      "[04-05 11:07:57] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 70000 lines\n",
      "[04-05 11:07:57] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 80000 lines\n",
      "[04-05 11:07:57] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 90000 lines\n",
      "[04-05 11:07:57] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 100000 lines\n",
      "[04-05 11:07:57] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 110000 lines\n",
      "[04-05 11:07:57] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 120000 lines\n",
      "[04-05 11:07:57] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 130000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 140000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 150000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 160000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 170000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 180000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 190000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 200000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 210000 lines\n",
      "[04-05 11:07:58] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 220000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 230000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 240000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 250000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 260000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 270000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 280000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 290000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 300000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 310000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 320000 lines\n",
      "[04-05 11:07:59] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 330000 lines\n",
      "[04-05 11:08:00] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 340000 lines\n",
      "[04-05 11:08:00] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 350000 lines\n",
      "[04-05 11:08:00] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 360000 lines\n",
      "[04-05 11:08:00] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 370000 lines\n",
      "[04-05 11:08:00] {/Users/yonatanlou/dev/QumranNLP/src/parsers/text_reader.py:60} INFO - processed 380000 lines\n"
     ]
    },
    {
     "data": {
      "text/plain": "       book scroll\n0               CD\n1               CD\n2               CD\n3               CD\n4               CD\n...     ...    ...\n342977         XQ8\n342978         XQ8\n342979         XQ8\n342980         XQ8\n342981         XQ8\n\n[342982 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book</th>\n      <th>scroll</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>CD</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>CD</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>CD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>CD</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>CD</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>342977</th>\n      <td></td>\n      <td>XQ8</td>\n    </tr>\n    <tr>\n      <th>342978</th>\n      <td></td>\n      <td>XQ8</td>\n    </tr>\n    <tr>\n      <th>342979</th>\n      <td></td>\n      <td>XQ8</td>\n    </tr>\n    <tr>\n      <th>342980</th>\n      <td></td>\n      <td>XQ8</td>\n    </tr>\n    <tr>\n      <th>342981</th>\n      <td></td>\n      <td>XQ8</td>\n    </tr>\n  </tbody>\n</table>\n<p>342982 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from src.parsers.text_reader import read_text\n",
    "\n",
    "from src.parsers.MorphParser import MorphParser\n",
    "\n",
    "text_file = f\"{BASE_DIR}/data/texts/abegg/dss_nonbib.txt\"\n",
    "yaml_dir = f\"{BASE_DIR}/data/yamls\"\n",
    "morph_parser = MorphParser(yaml_dir=yaml_dir)\n",
    "\n",
    "data, lines = read_text(text_file)\n",
    "\n",
    "\n",
    "res = []\n",
    "for i in data:\n",
    "    res.append({\"book\":i[\"book_name\"], \"scroll\":i[\"scroll_name\"]})\n",
    "df = pd.DataFrame(res)\n",
    "df\n",
    "#     \n",
    "# \n",
    "# logger.info(\"processed the following books}\")\n",
    "# for book in books_list:\n",
    "#     print(book, end=\",\")\n",
    "#     for entry in filtered_data[book]:\n",
    "#         entry[\"parsed_morph\"] = morph_parser.parse_morph(entry[\"morph\"])\n",
    "# return filtered_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T08:08:01.272568Z",
     "start_time": "2024-04-05T08:07:55.661990Z"
    }
   },
   "id": "169b1af57742c67d",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()[\"book\"].nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T08:08:51.908619Z",
     "start_time": "2024-04-05T08:08:51.842546Z"
    }
   },
   "id": "98aafa36e0b2123",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d619e1160cfdcd9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
